== Introduction

This section describes how Jenkins works with Cloud Pipelines.

IMPORTANT: You do not need to use all the pieces of Cloud Pipelines. You
can (and should) gradually migrate your applications to use those pieces of
Cloud Pipelines that you think best suit your needs.

=== Five-second Introduction

Cloud Pipelines Jenkins provides setup for Jenkins that creates jobs and pipelines
via Jenkins Job DSL or Jenkinsfile for your projects. The pipelines and
jobs use the scripts defined in
https://github.com/CloudPipelines/scripts[Cloud Pipelines Scripts] repo.

=== Five-minute Introduction

In these sections you will learn how exactly Cloud Pipelines Jenkins integrates
with https://github.com/CloudPipelines/scripts[Cloud Pipelines Scripts] and how
you can setup deployment pipelines for each project.

==== How to Use It

The suggested approach is to use the <<project-crawler>> approach, where
we scan your organization for projects and create deployment pipeline for each.

Another approach is to pass an environment variable with a list of repositories
for which you would like the pipeline to be built.

==== How It Works

As the following image shows, Cloud Pipelines contains logic to generate a
pipeline and the runtime to execute pipeline steps.

image::{intro-root-docs}/how.png[title="How Cloud Pipelines works"]

Once a pipeline is created (for example, by using Jenkins Job DSL), when the jobs are ran, they clone or download Cloud Pipelines
code to run each step. Those steps run functions that are
defined in the `commons` module of Cloud Pipelines.

Cloud Pipelines performs steps to guess what kind of a project your
repository is (e.g. JVM or PHP) and what framework it uses (Maven or Gradle), and it
can deploy your application to a cloud (e.g. Cloud Foundry or Kubernetes)

[[project-crawler]]
=== Project Crawler

In Jenkins, you can generate the deployment pipelines by passing an environment variable
with a comma-separated list of repositories. This, however, does not scale. We would like to automatically fetch
a list of all repositories from a given organization and team.

To do so, we use the https://github.com/CloudPipelines/project-crawler[Project Crawler]
library, which can:

* Fetch all projects for a given organization.
* Fetch contents of a file for a given repository.

The following diagram depicts this situation:

[plantuml, crawler, png]
----
Jenkins->CloudPipes: Copy the seed job from the repo
Jenkins->Seed: Run seed job to generate Spinnaker pipelines and jobs
Seed->Github: Crawl org [foo] and fetch all repositories
Github->Seed: In org [foo] there [a,b,c] repos
Seed->Github: For each repo fetch pipeline descriptor
Github->Seed: There you go. [a] wants no [test] env, [b] no [stage] env, [c] wants all envs
Seed->Seed: Build pipelines. For [a] without [test], for [b] without [stage]. All for [c]
note left of Seed: By having descriptors, \nwe can tune the pipelines \nas the app wanted it to.
Seed->Seed: Build jobs / pipelines for [a,b,c] repos
----

Thanks to the Project Crawler, you can run the seed job, and ,automatically, all the new repositories
are picked and pipelines are created for them. Project Crawler supports repositories
stored at Github, Gitlab, and Bitbucket. You can also register your own implementation. See the
https://github.com/CloudPipelines/project-crawler[Project Crawler] repository for more information.

[[how-do-the-scripts-work-with-spinanker]]
=== How Scripts Work with Spinnaker

With Spinnaker, the deployment pipeline is inside of Spinnaker. No longer do we treat
Jenkins as a tool that does deployments. In Jenkins, we create only
the CI jobs (that is, build and test) and prepare the JSON definitions of Spinnaker pipelines.

The following diagram shows how Jenkins, the seed job for Spinnaker, and Spinnaker cooperate:

[plantuml, spinnaker, png]
----
Jenkins->CloudPipes: Copy the seed job from the repo
Jenkins->Seed: Run seed job to generate Spinnaker pipelines and jobs
Seed->Github: Crawl org [foo] and fetch all repositories
Github->Seed: In org [foo] there [a,b,c] repos
Seed->Github: For each repo fetch pipeline descriptor
Github->Seed: There you go. [a] wants no [test], [b] no [stage], [c] wants all
Seed->Seed: Build pipelines. For [a] without [test], for [b] without [stage]. All for [c]
note left of Seed: By having descriptors, \nwe can tune the pipelines \nas the app wanted it to.
Seed->Seed: Build CI jobs for [a,b,c] repos
Seed->Seed: Build Spinnaker pipelines JSON definitions
Seed->Jenkins: Seed job done
Jenkins->Spinnaker: Upload JSON pipelines to Spinnaker
Spinnaker->Spinnaker: The pipelines for [a,b,c] successfully created
Spinnaker->Jenkins: Waiting for [spinnaker-a-build] build to start & complete
Jenkins->Jenkins: New commit! Running a build [spinnaker-a-build]
Jenkins->CloudPipes: Run the [build_and_upload.sh] script
note right of CloudPipes: Proceed with all the sourcing\n depending on language etc.
CloudPipes->Jenkins: Build completed!
Jenkins->Spinnaker: [spinnaker-a-build] started and completed
note right of Spinnaker: Running the rest of the pipeline!
Spinnaker->Spinnaker: Pipeline for [a] in progress. Deploy [a] to test env
Spinnaker->Jenkins: Calling [spinnaker-a-test-on-test] to run test on test
Jenkins->Spinnaker: [spinnaker-a-test-on-test] started and completed
Spinnaker->Spinnaker: ... we continue like this throughout the pipeline ...
Spinnaker->Spinnaker: ... and the pipeline is done
----
